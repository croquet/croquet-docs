Copyright Â© 2020 Croquet Studios

In this tutorial we will implement a multi-user whiteboard app. This will be a showcase of breaking up more complex application state into several models and submodels and correspondingly breaking up the view side into several components, now with "smart" subcomponents, each independently taking care of communication with their correpsonding submodel.

<iframe
     src="https://codesandbox.io/embed/whiteboard-mcoei?fontsize=14&module=%2Findex.jsx&theme=light"
     style="width:100%; height:500px; border:0; border-radius: 4px; overflow:hidden;"
     title="whiteboard"
     allow="geolocation; microphone; camera; midi; vr; accelerometer; gyroscope; payment; ambient-light-sensor; encrypted-media; usb"
     sandbox="allow-modals allow-forms allow-popups allow-scripts allow-same-origin"
   ></iframe>

In this simple sketch of a whiteboard app, you can double click white space to create a random shape or text object, which can be dragged, selected, resized and edited. All this works collaboratively with multiple users editing the board at the same time.

We will see how we can split all this behavior up into sensible model and view implementations and how we can reuse common functionality between them.

On the highest level, we just want to keep track of all objects (we'll call them "shapes") that have been added to the whiteboard. Our whiteboard model has a single observable property `shapes`:

```
class WhiteboardModel extends AutoObservableModel({ shapes: [] }) {
```

We define handlers for shape add and remove events. Note how in `addShape` we actually create whole new (sub-) models to represent each shape. In `removeShape`, we remove shapes based on their model id, since using indices in the event might lead to race conditions and concurrency issues when several users remove shapes at the same time.

```
init() {
  super.init();
  this.subscribe("shape", "add", this.addShape);
  this.subscribe("shape", "remove", this.removeShape);
}

addShape(shape) {
  if (shape.type === "rect") {
    this.shapes.push(Rect.create(shape));
  } else if (shape.type === "oval") {
    this.shapes.push(Oval.create(shape));
  } else if (shape.type === "text") {
    this.shapes.push(Text.create(shape));
  }
}

removeShape(id) {
  const index = this.shapes.findIndex(shape => shape.id === id);
  if (index !== -1) {
    this.shapes = this.shapes
      .slice(0, index)
      .concat(this.shapes.slice(index + 1));
  }
}
```

Before we look at the implementation of `Rect`, `Oval` and `Text` models, let's think what they all have in common: we want to position and resize them on the board. To implement this reusable behaviour, we specify the state of a positionable shape and define a `Positionable` mixin based on it. As you will see later, it is invoked like this: `class ShapeClass extends Positionable(Model)`.

```
const PositionableState = {
  x: 0,
  y: 0,
  width: 0,
  height: 0,
  rot: 0
};

function Positionable(BaseClass) {
  return class extends AutoObservable(PositionableState)(BaseClass) {
    init(options) {
      super.init(options);
      this.x = options.x;
      this.y = options.y;
      this.width = options.width;
      this.height = options.height;
      this.rot = options.rot || 0;

      this.subscribe(this.id, "move", this.move);
      this.subscribe(this.id, "setWidth", this.setWidth);
      this.subscribe(this.id, "setHeight", this.setHeight);
    }

    move({ x, y }) {
      this.x = x;
      this.y = y;
    }

    setWidth(width) {
      this.width = width;
    }

    setHeight(height) {
      this.height = height;
    }
  };
}
```

Another common trait (at least between `Rect` and `Oval`) will be that they can both be assigned colors. Very similarly to `Positionable`, we define the even simpler `Colorable` mixin. Here, we allow the class that uses the mixin to define several named color slots to be used for different color aspects (such as background or outline color).

```
function Colorable(colorSpecAndInit) {
  return BaseClass =>
    class extends AutoObservable(colorSpecAndInit)(BaseClass) {
      init(options) {
        super.init(options);
        this.setColors(options);
        this.subscribe(this.id, "setColors", this.setColors);
      }

      setColors(colorByName) {
        for (let [name, value] of Object.entries(colorByName)) {
          if (name in colorSpecAndInit) this[name] = value;
        }
      }
    };
}
```

The surprising thing is now that `Rect`s and `Oval`s are actually nothing more than positionable and colorable objects, at least as far as the model side is concerned.

```
class Rect extends Colorable({ backgroundColor: "#000" })(
  Positionable(Model)
) {}


class Oval extends Colorable({ backgroundColor: "#000" })(
  Positionable(Model)
) {}
```

Text shapes are only positionable (for this simple tutorial), but they do bring a tiny bit of custom behaviour, to set their text.

```
class Text extends Positionable(AutoObservableModel({ text: "" })) {
  init(options) {
    super.init(options);
    if (options.text) this.text = options.text;
    this.subscribe(this.id, "setText", this.setText);
  }

  setText(text) {
    this.text = text;
  }
}
```

That's all we need on the model side! On the view side, we start as always with our top-level component for starting the croquet session.

```
function WhiteboardApp() {
  return (
    <InCroquetSession name="whiteboard9" modelRoot={WhiteboardModel}>
      <Canvas />
    </InCroquetSession>
  );
}
```

Our main view component will be the `Canvas`, which acts as a container for our shapes. It observes the `shapes` property on our root `WhiteboardModel`:

```
function Canvas() {
  const model = useModelRoot();
  const { shapes } = useObservable(model);
```

It then defines a publish callback that sends a randomized shape add event to the model, picking first an arbitrary shape type, then position and size and potentially color. In an actual app, we would obviously have UI for adding shapes of each type, but to keep things simple and still allow us to experiment with shapes, we'll use this silly random-shape adder.

```
const publishAddShape = usePublish(
  event => [
    "shape",
    "add",
    Math.random() > 0.8
      ? {
          type: Math.random() > 0.5 ? "rect" : "oval",
          x: event.clientX,
          y: event.clientY,
          width: Math.random() * 100 + 15,
          height: Math.random() * 100 + 15,
          rot: Math.random() * 360,
          backgroundColor: `hsl(${Math.random() * 360}, 50%, 50%)`
        }
      : {
          type: "text",
          x: event.clientX,
          y: event.clientY,
          width: Math.random() * 100 + 15,
          height: Math.random() * 100 + 15,
          text: "Lorem ipsum dolor sit amet"
        }
  ],
  []
);
```

`Canvas` returns a SVG element, since that is how we will draw our shapes. If the SVG element registers a double click, it will call our `publishAddShape` callback.

Inside the SVG element, we iterate over all shapes in the shape list we got from the model. For each shape (which is a model itself!) we create an instance of the appropriate view component and pass the shape model to it.

Since all shape types can be positioned and resized in the same way, we'll also try to reuse the UI behavior for that in the view. The way we do this here is by wrapping the shape view components in a `PositioningFrame`, which will be responsible for just that part of user interaction with a shape.

```
return (
  <svg width="1000" height="1000" onDoubleClick={publishAddShape}>
    {shapes.map(shape => {
      let inner;
      if (shape instanceof Rect) inner = <RectView rect={shape} />;
      if (shape instanceof Oval) inner = <OvalView oval={shape} />;
      if (shape instanceof Text) inner = <TextView text={shape} />;
      return (
        <PositioningFrame key={shape.id} shape={shape}>
          {inner}
        </PositioningFrame>
      );
    })}
  </svg>
);
```

Now let's look at `PositioningFrame`. It takes care not only of resizing and positioning of a shape, but also maintains the current interaction state that the user has with the shape, resulting in a modal user interface.

It takes two parameters, `shape` which has to be a shape model that mixes in `Positionable`, and `children`, which are child components representing the concrete shape visually, which should be framed by this `PositioningFrame`.

We observe the positioning-relevant properties of our shape, to keep the frame up-to-date with the model.

```
function PositioningFrame({ shape, children }) {
  const { x, y, rot, width, height } = useObservable(shape);
```

We define a `groupRef` reference, which will point to the SVG group containing all UI elements of our `PositioningFrame`. We need this for measurement purposes when interpreting mouse events. For similar purposes, we keep track of where the mouse was last pressed down. Finally, we define the `interactionState` state variable, which will keep track of which interaction mode the user is currently in with respect to the framed shape.

```
const groupRef = useRef(null);
const [mouseDownAt, setMouseDownAt] = useState(null);
const [interactionState, setInteractionState] = useState(null);
```

We define a `publishMove` callback here, since dragging the whole frame to move an object will be the only mouse interaction that the `PositioningFrame` is directly responsible for (the rest will be handled by further subcomponents).

```
const publishMove = usePublish((x, y) => [shape.id, "move", { x, y }], []);
```

We continue by implementing handlers for all kinds of mouse events, implementing dragging as well as interaction mode changes through clicking on an object - and dismissing the object when clicking elsewhere.

```
const onMouseDown = useCallback(
  event => {
    setMouseDownAt({
      x: event.clientX,
      y: event.clientY,
      rectStartX: x,
      rectStartY: y
    });
    event.preventDefault();
  },
  [setMouseDownAt, x, y]
);

const onMouseUp = useCallback(
  event => {
    if (mouseDownAt) {
      event.preventDefault();
      setMouseDownAt(null);
    }
    event.stopPropagation();
  },
  [setMouseDownAt, mouseDownAt]
);

const onMouseMove = useCallback(
  event => {
    if (mouseDownAt) {
      const grabOffsetX = mouseDownAt.x - mouseDownAt.rectStartX;
      const grabOffsetY = mouseDownAt.y - mouseDownAt.rectStartY;
      publishMove(event.clientX - grabOffsetX, event.clientY - grabOffsetY);
      event.preventDefault();
    }
  },
  [mouseDownAt, publishMove]
);

const onMouseEnter = useCallback(() => {
  if (interactionState === null) setInteractionState("hover");
}, [interactionState]);
const onMouseLeave = useCallback(() => {
  if (interactionState === "hover") setInteractionState(null);
}, [interactionState]);
const onClick = useCallback(
  event => {
    if (
      mouseDownAt &&
      (Math.abs(event.clientX - mouseDownAt.x) > 5 ||
        Math.abs(event.clientY - mouseDownAt.y) > 5)
    ) {
      event.stopPropagation();
    } else {
      if (interactionState === "hover") setInteractionState("move");
      if (interactionState === "move") {
        setInteractionState("edit");
        // hack to select any child text fields
        const contentEditableChild = groupRef.current.querySelector(
          "[contenteditable]"
        );
        if (contentEditableChild) contentEditableChild.focus();
        event.stopPropagation();
      }
      if (interactionState === "edit") {
        event.stopPropagation();
      }
    }
  },
  [interactionState, mouseDownAt]
);

const onClickElsewhere = useCallback(() => {
  if (interactionState === "move" || interactionState === "edit")
    setInteractionState(null);
}, [interactionState]);
```

We also define a `publishRemove` callback to send a shape remove message to the root `WhiteboardModel` and set up a key handler to call this callback when backspace or delete keys are pressed and we are interacting with this shape.

```
const publishRemove = usePublish(() => ["shape", "remove", shape.id], [
  shape.id
]);

const onKeyDown = useCallback(
  event => {
    const key = event.keyCode;
    if (interactionState === "move" && (key === 8 || key === 46)) {
      publishRemove();
    }
  },
  [interactionState, publishRemove]
);
```

We use `useEffect` two times to hook up (and later clean up) our event listeners to the appropriate DOM elements (either our SVG group, or the whole document, to capture events outside the frame when needed).

```
useEffect(() => {
  const group = groupRef.current;
  group.addEventListener("click", onClick);
  document.addEventListener("click", onClickElsewhere);
  document.addEventListener("keydown", onKeyDown);

  return () => {
    group.removeEventListener("click", onClick);
    document.removeEventListener("click", onClickElsewhere);
    document.removeEventListener("keydown", onKeyDown);
  };
});

useEffect(() => {
  document.addEventListener("mousemove", onMouseMove);
  document.addEventListener("mouseup", onMouseUp);

  return () => {
    document.removeEventListener("mousemove", onMouseMove);
    document.removeEventListener("mouseup", onMouseUp);
  };
}, [onMouseMove, onMouseUp]);
```

Now, we will be organising the sub-elements and sub-components of our `PositioningFrame` based on whether they should appear visually behind or in front of the actual shape view component.

```
let editControls = [];
let bgEditControls = [];
```

Which controls and thus sub-components are available depends on the current interaction state of the user with respect to the framed shape. If the user is hovering the shape, we only display a grey outline rectangle and a grey filled rectangle in the foreground, to visually show the shapes spatial extent, to give interaction affordance and to capture mouse down events (potential click or drag start) over the whole area of the shape:

```
if (interactionState === "hover") {
  editControls = [
    <rect
      x={-width / 2 - RESIZE_CORNER_DIST}
      y={-height / 2 - RESIZE_CORNER_DIST}
      width={width + 2 * RESIZE_CORNER_DIST}
      height={height + 2 * RESIZE_CORNER_DIST}
      stroke="#00000055"
      fill="transparent"
      strokeWidth="1"
    />,
    <rect
      x={-width / 2}
      y={-height / 2}
      width={width}
      height={height}
      fill="#00000022"
      strokeWidth="1"
      onMouseDown={onMouseDown}
    />
  ];
```

If the user is already in the `"selected"` state, we render a blue outline and 4 `ResizeCorner` sub-components, to which we pass just enough positional reference information so they can interpret drag events and resize the shape in the model independently (we will see how).

```
} else if (interactionState === "selected") {
  editControls = [
    <rect
      x={-width / 2 - RESIZE_CORNER_DIST}
      y={-height / 2 - RESIZE_CORNER_DIST}
      width={width + 2 * RESIZE_CORNER_DIST}
      height={height + 2 * RESIZE_CORNER_DIST}
      stroke="#00f"
      fill="transparent"
      strokeWidth="1"
    />,
    <ResizeCorner
      x={-width / 2}
      y={-height / 2}
      cx={x}
      cy={y}
      rot={rot}
      id={shape.id}
    />,
    <ResizeCorner
      x={width / 2}
      y={-height / 2}
      cx={x}
      cy={y}
      rot={rot}
      id={shape.id}
    />,
    <ResizeCorner
      x={width / 2}
      y={height / 2}
      cx={x}
      cy={y}
      rot={rot}
      id={shape.id}
    />,
    <ResizeCorner
      x={-width / 2}
      y={height / 2}
      cx={x}
      cy={y}
      rot={rot}
      id={shape.id}
    />,

    <rect
      x={-width / 2}
      y={-height / 2}
      width={width}
      height={height}
      fill="#00000022"
      strokeWidth="1"
      onMouseDown={onMouseDown}
    />
  ];
}
```

Finally, if we are in the `"edit"` interaction state, we only draw a red outline, in the background this time - to not interfere with any mouse events on the shape view component itself (such as text selection for a `TextView`).

```
} else if (interactionState === "edit") {
  bgEditControls = [
    <rect
      x={-width / 2 - RESIZE_CORNER_DIST}
      y={-height / 2 - RESIZE_CORNER_DIST}
      width={width + 2 * RESIZE_CORNER_DIST}
      height={height + 2 * RESIZE_CORNER_DIST}
      stroke="#f00"
      fill="transparent"
      strokeWidth="1"
    />
  ];
}
```

As mentioned, `PositioningFrame` returns a SVG group, containing both the interaction controls, as well as the view subcomponent (`children`), already correctly positioned.

```
return (
  <g
    ref={groupRef}
    transform={`translate(${x}, ${y}) rotate(${rot})`}
    onMouseEnter={onMouseEnter}
    onMouseLeave={onMouseLeave}
  >
    {bgEditControls}
    {children}
    {editControls}
  </g>
);
```

Next, we'll look at the implementation of a `ResizeCorner`, which knows how to render itself in the correct position and how to interpret mouse events in the positional reference frame of its parent `PositioningFrame` - which it gets passed as parameters. There is nothing really new here. The only noteworthy thing is that this is a "publish only" component - it gets passed observed model state from its parent compontent and is "dumb" in this regard, but does know how to publish correct `setWidth` and `setHeight` events to its shape model - so in this regard it is a "smart" component.

```
const RESIZE_CORNER_SIZE = 6;
const RESIZE_CORNER_DIST = 4;

function ResizeCorner({ x, y, cx, cy, rot, id }) {
  const [mouseDown, setMouseDown] = useState(null);
  const publishWidth = usePublish(width => {
    return [id, "setWidth", width];
  }, []);
  const publishHeight = usePublish(height => {
    return [id, "setHeight", height];
  }, []);

  const onMouseDown = useCallback(
    event => {
      setMouseDown(true);
      event.stopPropagation();
    },
    [setMouseDown]
  );

  const onMouseUp = useCallback(
    event => {
      if (mouseDown) {
        event.preventDefault();
        setMouseDown(false);
      }
      event.stopPropagation();
    },
    [setMouseDown, mouseDown]
  );

  const onMouseMove = useCallback(
    event => {
      if (mouseDown) {
        const newCornerX = event.clientX;
        const newCornerY = event.clientY;
        const centerToNewCorner = [newCornerX - cx, newCornerY - cy];
        const angleRadians = (2 * Math.PI * rot) / 360;
        const alongHeight = [-Math.sin(angleRadians), Math.cos(angleRadians)]; // unit length
        const alongWidth = [Math.cos(angleRadians), Math.sin(angleRadians)]; // unit length

        const projectedAlongHeight =
          centerToNewCorner[0] * alongHeight[0] +
          centerToNewCorner[1] * alongHeight[1];
        const projectedAlongWidth =
          centerToNewCorner[0] * alongWidth[0] +
          centerToNewCorner[1] * alongWidth[1];

        publishWidth(Math.abs(projectedAlongWidth * 2 - RESIZE_CORNER_DIST));
        publishHeight(Math.abs(projectedAlongHeight * 2 - RESIZE_CORNER_DIST));
      }
    },
    [mouseDown, publishWidth, publishHeight, cx, cy, rot]
  );

  useEffect(() => {
    document.addEventListener("mousemove", onMouseMove);
    document.addEventListener("mouseup", onMouseUp);

    return () => {
      document.removeEventListener("mousemove", onMouseMove);
      document.removeEventListener("mouseup", onMouseUp);
    };
  }, [onMouseMove, onMouseUp]);

  return (
    <rect
      x={x - RESIZE_CORNER_SIZE / 2 + Math.sign(x) * RESIZE_CORNER_DIST}
      y={y - RESIZE_CORNER_SIZE / 2 + Math.sign(y) * RESIZE_CORNER_DIST}
      width={RESIZE_CORNER_SIZE}
      height={RESIZE_CORNER_SIZE}
      stroke="#00f"
      fill="#00f"
      strokeWidth="1"
      style={{ cursor: "pointer" }}
      onMouseDown={onMouseDown}
    />
  );
}
```

Now let's look at the actual components for rendering `Rect`s and `Oval`s. It turns out that after the `PositioningFrame` taking care of so much, there is nothing left to implement other than the visual peculiarities of each shape - which are easily expressed in SVG. Note that both components do observe relevant properties from their passed shape model, and are "smart" in this regard.

```
function RectView({ rect }) {
  const { width, height, backgroundColor } = useObservable(rect);

  return (
    <rect
      x={-width / 2}
      y={-height / 2}
      width={width}
      height={height}
      stroke="black"
      fill={backgroundColor}
      strokeWidth="5"
    />
  );
}

function OvalView({ oval }) {
  const { width, height, backgroundColor } = useObservable(oval);

  return (
    <ellipse
      cx={0}
      cy={0}
      rx={width / 2}
      ry={height / 2}
      stroke="black"
      fill={backgroundColor}
      strokeWidth="5"
    />
  );
}
```

Only the `TextView` is a bit more involved, because we use a `contenteditable` div (tamed for React use in the `ContentEditable` component) **inside** SVG, which requires use of the `foreignObject` element. All the rest (observing properties and publishing events based on user input) should look familiar to you by now.

```
function TextView({ text: textShape }) {
  const { width, height, text } = useObservable(textShape);
  const onInput = usePublish(html => {
    return [textShape.id, "setText", html];
  }, []);

  return (
    <foreignObject x={-width / 2} y={-height / 2} width={width} height={height}>
      <div xmlns="http://www.w3.org/1999/xhtml">
        <ContentEditable html={text} onChange={onInput} />
      </div>
    </foreignObject>
  );
}

class ContentEditable extends React.Component {
  constructor(props) {
    super(props);
    this.elRef = React.createRef();
    this.state = { editing: false };
  }

  render() {
    return (
      <div
        onInput={() => this.emitChange(false)}
        onBlur={() => this.emitChange(true)}
        ref={this.elRef}
        contentEditable
        dangerouslySetInnerHTML={{ __html: this.props.html }}
      />
    );
  }
  shouldComponentUpdate(nextProps, nextState) {
    if (this.state.editing) {
      if (!nextState.editing) return true;
      return false;
    } else {
      return nextProps.html !== this.elRef.current.innerHTML;
    }
  }
  emitChange(done) {
    if (done) this.setState({ editing: false });
    else this.setState({ editing: true });
    var html = this.elRef.current.innerHTML;
    if (this.props.onChange && html !== this.lastHtml) {
      this.props.onChange(html);
    }
    this.lastHtml = html;
  }
}
```

This concludes our most complex demo for `@croquet/react` to date and should hopefully serve as a recipe for building pretty complex apps, with many interactive objects, different interaction modes and smart behaviour re-use and delegation on both the model and view side.
